{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sy\n",
    "sy.init_session(quiet = True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diferenciación numérica\n",
    "\n",
    "En el siguiente cuaderno se realizará una exploración en la diferenciación numérica mediante el método de diferencias finitas. Pondremos nuestra atención en la función\n",
    "\n",
    "# $$f(x) = cosh^{-1}(x)$$\n",
    "\n",
    "Es decir, en el coseno hiperbólico inverso. En la siguiende celda asociamos la variable f a esta función, la cual se encuentra ya definida en la librería numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.arccosh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diferenciación por diferencias finitas\n",
    "\n",
    "Este método permite encontrar aproximaciones a las derivadas de funciones en puntos específicos, sin necesidad de encontrar una derivada general para la función. Estas aproximaciones se basan en despejar las distintas derivadas que surgen a partir de la serie de Taylor asociada a la función. Para cada función existen muchas aproximaciones posibles, cada una mejor que la anterior. En este cuaderno se utilizará una aproximación de orden 2. Recordemos que la definición de derivada de una función es \n",
    "\n",
    "# $$f'(x) = lim_{h \\to 0}\\dfrac{f(x + h) - f(x)}{h}.$$\n",
    "\n",
    "Observemos que la derivada se define para el caso en el que $h$ se acerca a cero (sin llegar a serlo). Por lo tanto, en el método de diferencias finitas, usaremos un método similar para encontrar el valor de la derivada en un punto específico, pero en lugar de usar el concepto de límite, usaremos valores pequeños para $h$. Estos valores reciben el nombre de *tamaño de paso*. A la hora de llegar a estas aproximaciones, de manera análoga a hallar límites por izquierda y derecha, tenemos aproximaciones las cuales se basan en aproximar el valor de $h$, por la atrás, por adelante, o de forma centrada en el caso de usar ambas. A cada una de estas aproximaciones le corresponde una formula distinta. Usaremos la siguiente convención \n",
    "\n",
    "$$x_{i + 1} = x_{i} + h$$\n",
    "$$x_{i - 1} = x_{i} - h,$$\n",
    "\n",
    "donde $x_{0}$ es el punto en el cual estamos hallando la derivada de la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aproximación de la primera derivada\n",
    "\n",
    "Para la aproximación de la primera derivada, usaremos las siguientes fórmulas:\n",
    "\n",
    "### Aproximación por atrás\n",
    "\n",
    "#### $$f'(x) \\approx \\dfrac{3f(x_{i}) - 4f(x_{i - 1}) + f(x_{i - 2})}{2h}$$\n",
    "\n",
    "### Aproximación centrada\n",
    "\n",
    "#### $$f'(x) \\approx \\dfrac{-f(x_{i + 2}) + 8f(x_{i + 1}) - 8f(x_{i - 1}) + f(x_{i - 2})}{12h}$$\n",
    "\n",
    "### Aproximación por adelante\n",
    "\n",
    "#### $$f'(x) \\approx \\dfrac{-f(x_{i + 2}) + 4f(x_{i + 1}) - 3f(x_{i})}{2h}$$\n",
    "\n",
    "En la siguiente celda de código, definimos todas estas funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_prima_atras(f, x, h):\n",
    "    \n",
    "    return (3*f(x) - 4*f(x - h) + f(x - 2*h)) / (2*h)\n",
    "\n",
    "def f_prima_centrada(f, x, h):\n",
    "    \n",
    "    return (-f(x + 2*h) + 8*f(x + h) - 8*f(x - h) + f(x - 2*h)) / (12*h)\n",
    "\n",
    "\n",
    "def f_prima_adelante(f, x, h):\n",
    "    \n",
    "    return (-f(x + 2*h) + 4*f(x + h) - 3*f(x)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aproximación de la segunda derivada\n",
    "\n",
    "De la misma forma en la que podemos obtener fórmulas para aproximar la primera derivada de una función, también tenemos fórmulas para encontrar la segunda derivada de una función. Es importante observar que estas fórmulas no dependen en hallar la segunda derivada de la función. Las fórmulas para hallar la segunda derivada de una función mediante el método de diferencias finitas son las siguientes:\n",
    "\n",
    "### Aproximación por atrás\n",
    "\n",
    "####  $$f''(x) \\approx \\dfrac{2f(x_{i}) - 5f(x_{i - 1}) + 4f(x_{i - 2}) - f(x_{i - 3})}{h^{2}}$$\n",
    "\n",
    "### Aproximación centrada\n",
    "\n",
    "####  $$f''(x) \\approx \\dfrac{-2f(x_{i + 2}) + 16f(x_{i  + 1}) - 30f(x_{i}) + 16f(x_{i - 1}) - f(x_{i - 2})}{12h^{2}}$$\n",
    "\n",
    "### Aproximación por adelante\n",
    "\n",
    "####  $$f''(x) \\approx \\dfrac{-f(x_{i + 3}) + 4f(x_{i  + 2}) - 5f(x_{i + 1}) + 2f(x_{i})}{h^{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segunda derivada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_segunda_atras(f, x, h):\n",
    "    \n",
    "    return (2*f(x) - 5*f(x - h) + 4*f(x - 2*h) - f(x - 3*h)) / (h**2)\n",
    "\n",
    "def f_segunda_centrada(f, x, h):\n",
    "    \n",
    "    return (-f(x + 2*h) + 16*f(x + h) - 30*f(x) + 16*f(x - h) - f(x - 2*h)) / (12*h**2)\n",
    "\n",
    "def f_segunda_adelante(f, x, h):\n",
    "    \n",
    "    return (-f(x + 3*h) + 4*f(x + 2*h) - 5*f(x + h) + 2*(f(x))) / h**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "funciones_1 = [f_prima_atras, f_prima_centrada, f_prima_adelante]\n",
    "funciones_2 = [f_segunda_atras, f_segunda_centrada, f_segunda_adelante]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función nos permitirá imprimir tablas para analizar los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_tabla(funciones, valor_real, mensaje):\n",
    "\n",
    "    tam_pasos = [0.5, 0.05, 0.01]\n",
    "\n",
    "    resultados = []\n",
    "    error_relativo = []\n",
    "    for f_ in funciones:\n",
    "\n",
    "        aux = []\n",
    "        aux_error = []\n",
    "\n",
    "        for h in tam_pasos:\n",
    "\n",
    "            aproximacion = f_(f, x, h)\n",
    "\n",
    "            aux.append(aproximacion)\n",
    "            aux_error.append(abs((valor_real - aproximacion) / valor_real))\n",
    "\n",
    "        resultados.append(aux)\n",
    "        error_relativo.append(aux_error)         \n",
    "\n",
    "\n",
    "    print(f'Resultados calculando la {mensaje} derivada por diferencias finitas\\n')\n",
    "    print('            0.5              0.05                0.01\\n')\n",
    "    print('Atrás     ', resultados[0])\n",
    "    print('Centrada  ', resultados[1])\n",
    "    print('Adelante  ', resultados[2])\n",
    "    print('\\nRespuesta analítica: ', primera_deriv_real )\n",
    "\n",
    "    print(f'\\nError relativo de la {mensaje} derivada por diferencias finitas\\n')\n",
    "    print('            0.5              0.05                0.01\\n')\n",
    "    print('Atrás     ', error_relativo[0])\n",
    "    print('Centrada  ', error_relativo[1])\n",
    "    print('Adelante  ', error_relativo[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obteniendo la respuesta analítica\n",
    "\n",
    "Para poder saber que tan bién estamos aproximando la función, necesitamos tener el marco de referencia el cual es, las respuestas analíticas. Para hallar las derivadas de forma analítica, usaremos la libreria Sympy. Recordemos que estamos hallando la derivada de la función en $x = 1.33$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando en x = 1.33\n",
      "\n",
      "Primera derivada:  1.14042064190079\n",
      "Segunda derivada:  -1.97263552312140\n"
     ]
    }
   ],
   "source": [
    "x = 1.33\n",
    "\n",
    "primera_deriv_real = sy.diff(sy.acosh(y)).subs({y: x}).evalf()\n",
    "segunda_deriv_real = sy.diff(sy.acosh(y), y, 2).subs({y: x}).evalf()\n",
    "\n",
    "print('Evaluando en x = 1.33')\n",
    "print('\\nPrimera derivada: ', primera_deriv_real)\n",
    "print('Segunda derivada: ', segunda_deriv_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabla de resultados\n",
    "\n",
    "Ahora que tenemos las respuestas analíticas, vamos a imprimir la tabla de resultados, para comparar que tan buenas son las distintas aproximaciones de la primera y segunda derivada de la función $cosh^{-1}(x)$ mediante el método de diferencias finitas. Vamos a calcular la primera y segunda derivada para los siguientes tamaños de paso: $h = 0.5$, $h = 0.05$ y $h = 0.01$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados de la primera derivada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados calculando la primera derivada por diferencias finitas\n",
      "\n",
      "            0.5              0.05                0.01\n",
      "\n",
      "Atrás      [nan, 1.1304159107648004, 1.1401116593307559]\n",
      "Centrada   [nan, 1.1402665552554963, 1.1404204113019845]\n",
      "Adelante   [0.9867337109033185, 1.1347663556843246, 1.1401444589405063]\n",
      "\n",
      "Respuesta analítica:  1.14042064190079\n",
      "\n",
      "Error relativo de la primera derivada por diferencias finitas\n",
      "\n",
      "            0.5              0.05                0.01\n",
      "\n",
      "Atrás      [nan, 0.00877284290409849, 0.000270937370544538]\n",
      "Centrada   [nan, 0.000135113869066862, 2.02205041058565e-7]\n",
      "Adelante   [0.134763371821569, 0.00495807074049304, 0.000242176395387357]\n"
     ]
    }
   ],
   "source": [
    "imprimir_tabla(funciones_1, primera_deriv_real, 'primera')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizando los resultados de la segunda derivada\n",
    "\n",
    "Podemos observar que al evaluar al aproximar la primera derivada mediante la aproximación centrada y con un tamaño de paso de $h = 0.01$, obtenemos la respuesta mas cercana a la respuesta analítica, con un error relativo de $2.022 * (10)^{-7}$. También, podemos observar que al evaluar con un tamaño de paso de $h = 0.5$, obtenemos $nan$. La razón de esto, es que la función $cosh^{-1}(x)$ no está definida para los valores en los cuales se está calculando la derivada. Este fenómeno también se puede apreciar en los resultados de la segunda derivada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados de la segunda derivada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados calculando la segunda derivada por diferencias finitas\n",
      "\n",
      "            0.5              0.05                0.01\n",
      "\n",
      "Atrás      [nan, -1.6702355708198888, -1.9658787664789124]\n",
      "Centrada   [nan, -1.9719331445193293, -1.9726344779674718]\n",
      "Adelante   [-0.8936877086760138, -1.8815389706258396, -1.9672691043792767]\n",
      "\n",
      "Respuesta analítica:  1.14042064190079\n",
      "\n",
      "Error relativo de la segunda derivada por diferencias finitas\n",
      "\n",
      "            0.5              0.05                0.01\n",
      "\n",
      "Atrás      [nan, 0.153297428114349, 0.00342524331702142]\n",
      "Centrada   [nan, 0.000356061012711696, 5.29826173628178e-7]\n",
      "Adelante   [0.546957510294712, 0.0461801237115595, 0.00272043095606163]\n"
     ]
    }
   ],
   "source": [
    "imprimir_tabla(funciones_2, segunda_deriv_real, 'segunda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizando los resultados de la segunda derivada\n",
    "\n",
    "Podemos observar que al evaluar al aproximar la segunda derivada mediante la aproximación centrada y con un tamaño de paso de $h = 0.01$, obtenemos la respuesta mas cercana a la respuesta analítica, con un error relativo de $5.2982 * (10)^{-7}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis final\n",
    "Observamos que en ambos casos, la mejor aproximacion se logra al usar la aproximación centrada con un tamaño de paso de $h = 0.01$. La razón de esto, es que al evaluar la derivada de forma centrada, estamos 'compensando' los errores que se presentan al evaluar por atrás y por adelante. Además, dado que el tamaño de paso que estamos usando en ambos casos es el menor  ($h = 0.01$), conseguimos una respuesta mucho más aproximada, ya que por la propia definición, la derivada se define como un límite cuando h se vuelve cada vez y más pequeña. En conclusión, a la hora de usar el método de la diferencias finitas para aproximar derivadas de funciones, debemos procurar en usar, cuando sea posible, la aproximación centrada, y en usar el menor tamaño de paso posible, puesto que para valores mas pequeños de $h$, la aproximación se hará arbitrariamente más precisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
